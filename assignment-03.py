# %% [markdown]
# ## Lecture-03 Gradient Descent and Dymanic Programming
# %% [markdown]
# In this week, we need complete following tasks:
# + Re-review the course online programming;
# + Choose 1 - 2 books which you interested and keep reading;
# + Answer the review questions
# + Prepare the basic requirement of our 1st project.
# %% [markdown]
# ### Part I Review the online programming.
# %%
import matplotlib.pyplot as plt
import random
from collections import defaultdict
from functools import wraps
# %%
original_price = [1, 5, 8, 9, 10, 17, 17, 20, 24, 30, 35]
price = defaultdict(int)
for i, p in enumerate(original_price):
    price[i+1] = p
# %%
called_time_with_arg = defaultdict(int)


def get_call_time(f):
    @wraps(f)
    def wrap(*args, **kwargs):
        result = f(*args, **kwargs)
        called_time_with_arg[(f.__name__, *args)] += 1
        return result
    return wrap


@get_call_time
def add_ten(n): return n+10


add_ten(10)
# %%
def memo(f):
    memo.already_computed = {}
    @wraps(f)
    def _wrap(arg):
        result = None

        if arg in memo.already_computed:
            result = memo.already_computed[arg]
        else:
            result = f(arg)
            memo.already_computed[arg] = result
        return result
    return _wrap

@memo
@get_call_time
def r(n):
    max_price, max_split = max([(price[0]+price[n],0)]+[(r(i)+r(n-i), i)
                                                for i in range(1,n)], key=lambda x: x[0])
    solution[n] = (n-max_split, max_split)
    return max_price


# %%
solution = [0]*30
r(12)
called_time_with_arg
#%% 
def parse_solution(solution ,length):
    left,right = solution[length]

    if right==0: return [left]
    return parse_solution(solution ,left)+parse_solution(solution,right)
parse_solution(solution,5)

# %% [markdown]
# ### Part 2: change loss function from $loss = \frac{1}{n}\sum{(y_i - (\hat{y_i}))^2}$ to $loss = \frac{1}{n}\sum{|y_i - \hat{y_i}|}$, and using your mathmatical knowledge to get the right partial formual. Implemen the gradient descent code.
# $$ {{\partial L(k,b)} \over {\partial k}} = \sum { 1 \over n } a*x_i $$  
# $$ {{\partial L(k,b)} \over {\partial b}} = \sum {1 \over n } a             $$
# `a = 1 if yi > y_hat else -1`   
#%%
def abs_error(y,y_hat):
    assert len(y)==len(y_hat)
    error = [abs(y[i]-y_hat[i]) for i in range(len(y))]
def abs_gradient(x,y,k,b):
    y_hat = [k*x[i]+b for i in range(len(x))]
    gradient_ks = [x[i] if y[i]-y_hat[i]>0 else -x[i] for i in range(len(x))]
    gradient_bs = [1 if y[i]-y_hat[i]>0 else -1 for i in range(len(x))]
    def mean(gradients):
        return sum(gradients)/len(gradients)
    return mean(gradient_ks),mean(gradient_bs)
# %% [markdown]
# ### Part 3: Finish the Solution Parse Part of Edit-Distance
#%%

def lru_cache(f):
    cache = {}
    @wraps(f)
    def wrap(str1,str2):
        if str1+str2 in cache:
            return cache[str1+str2]
        else:
            result = f(str1,str2)
            return result
    return wrap 


#%%
@lru_cache
def edit_distance(str1,str2):

    if len(str1)==0:
        return len(str2)
    if len(str2) == 0:
        return len(str1)
    tail_s1 = str1[-1]
    tail_s2 = str2[-1]
    ## distance has three options: delete , add , 
    candidates = [
        (edit_distance(str1[:-1],str2)+1,'DEL {}'.format(tail_s1)),
        (edit_distance(str1,str2[:-1])+1,"ADD {}".format(tail_s2))
    ]
    if tail_s1 == tail_s2:
        both_forward = (edit_distance(str1[:-1],str2[:-1])+0,'SAM SAM')
    else:
        both_forward = (edit_distance(str1[:-1],str2[:-1])+1,'SUB {}=>{}'.format(tail_s1,tail_s2))
    candidates.append(both_forward)

    min_distance,operation = min(candidates,key = lambda x : x[0])

    solution[(str1,str2)] = operation

    return min_distance 
solution = {}
edit_distance('GREET','GREAT')
# %%
def ed_parse_solution(str1,str2):
    if str1 =='' or str2 =='':
        return []
    ops = solution.get((str1,str2))
    if not ops:
        return []
    operator,*_ = ops.split(" ")
    if operator=="SUB" or operator=='SAM':
        str1 = str1[:-1]
        str2 = str2[:-1]
    elif operator == "ADD":
        str2 = str2[:-1]
    elif operator == "DEL":
        str1 = str1[:-1]
    return [ops]+ed_parse_solution(str1,str2)
ed_parse_solution("GREET","GREAT")


# %% [markdown]
# ### Part 4 Choose 1 - 2 books to keep reading:
# + SICP, Structure and Interpretation of Computer Programming.
# + Introduction to Algorithms
# + Artificial Intelligence A Modern Approach (3rd Edition)
# + Code Complete 2
# + Programming Pearls
# + Deep Learning
# + é»‘å®¢ä¸ç”»å®¶
# + æ•°å­¦ä¹‹ç¾
# + Fluent Python
# + Hands on Tensorflow
# + Conference: NIPS_ ICML_ ICLR_ ACL_ AAAI
#
# > most books you may find in our github: https://github.com/Computing-Intelligence/References
# %% [markdown]
# [x] fluent python 
# %% [markdown]
# ## Part 5-1: review machine learning
# %% [markdown]
# 1. Why do we use Derivative / Gredient to fit a target function?Â¶
# %% [markdown]
# Ans:å¯¼æ•°/æ¢¯åº¦å†³å®šäº†ä¸€ä¸ªå‡½æ•°æ²¿ç€æ–¹å‘è½´æ˜¯ä¸Šå‡è¿˜æ˜¯ä¸‹é™ã€‚å¦‚æœæˆ‘ä»¬æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘å‰è¿›
# å°±èƒ½æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ›´ä½ç‚¹ã€‚ä»è€Œä¸æ–­çš„ä¼˜åŒ–ã€‚
# %% [markdown]
# 2. In the words 'Gredient Descent', what's the Gredient and what's the Descent?Â¶
# %% [markdown]
# Ans: æ¢¯åº¦, æ˜¯ç›®æ ‡å‡½æ•°å¯¹æŸä¸ªæ–¹å‘è½´çš„å¾®åˆ†.æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘æ›´æ–°å‚æ•°, 
# å¯ä»¥è®©ç›®æ ‡å‡½æ•°çš„å€¼ä¸‹é™.å› æ­¤æ˜¯æ¢¯åº¦ä¸‹é™æ³•
# %% [markdown]
#
# 3. What's the advantages of the 3rd gradient descent method compared to the previous methods?
# %% [markdown]
# Ans:ç¡®ä¿äº†æ¯æ¬¡è¿­ä»£éƒ½èƒ½ç¦»æœ€ä¼˜ç‚¹/å±€éƒ¨æœ€ä¼˜ç‚¹ æ›´è¿›ä¸€æ­¥ã€‚ä»è€Œå‡å°‘è¿­ä»£æ¬¡æ•°ï¼Œ æˆ–è€…è¯´åœ¨ç›¸åŒè¿­ä»£æ¬¡æ•°ä¸‹ï¼Œæ‰¾åˆ°çš„ç‚¹æ›´ä¼˜
# %% [markdown]
# 4. Using the simple words to describe: What's the machine leanring.Â¶
# %% [markdown]
# Ans: é€šè¿‡æŸç§æ–¹æ³•å¯»æ‰¾åˆ°ä¸€ä¸ªèƒ½å¤Ÿæ‹Ÿåˆç‰¹å¾ä¸æ ‡ç­¾ä¹‹é—´æ˜ å°„å…³ç³»çš„å‡½æ•°ã€‚
# %% [markdown]
# ### Part 5: Answer following questions:
# %% [markdown]
# 1. Why do we need dynamic programming? What's the difference of dynamic programming and previous talked `search` problem?
#%% [markdown]
# Ans: ä¹‹å‰çš„è·¯å¾„æœç´¢é—®é¢˜ï¼Œ æˆ‘ä»¬åªæ˜¯ç®€å•åœ°è¿›è¡Œäº†é€’å½’æˆ–è¿­ä»£ã€‚åœ¨é€’å½’ä¸­ï¼Œå­˜åœ¨ç€é‡å¤è°ƒç”¨ç›¸åŒå‚æ•°å‡½æ•°çš„æƒ…å†µï¼Œå¸¦æ¥äº†å¾ˆå¤šçš„è®¡ç®—é‡ã€‚é€šè¿‡å»ºç«‹ä¸€ä¸ªè¡¨ï¼Œ
# è®©æ¯æ¬¡è°ƒç”¨å‰å…ˆæŸ¥è¡¨ï¼Œå¦‚æœæœ‰ï¼Œå°±ç›´æ¥è·å–è¡¨çš„å†…å®¹ï¼Œè€Œä¸æ˜¯è°ƒç”¨å‡½æ•°ã€‚ä»è€Œå‡å°‘äº†è°ƒç”¨æ¬¡æ•°ã€‚è¿™å°±æ˜¯åŠ¨æ€è§„åˆ’

# %% [markdown]
# 2. Why do we still need dynamic programming? Why not we train a machine learning to fit a function which could get the `riht` answer based on inputs?
#%% [markdown]
# åŠ¨æ€è§„åˆ’åœ¨æ±‚è§£å°è§„æ¨¡æ— ä¸ç¡®å®šæ€§é—®é¢˜æ—¶ï¼Œèƒ½å¤Ÿå¾—åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚ åœ¨æ—¶é—´å¤æ‚åº¦ä»¥åŠè§£çš„è´¨é‡ä¸Šè¦æ¯”æœºå™¨å­¦ä¹ å¥½ 
# %% [markdown]
# 3. Can you catch up at least 3 problems which could solved by Dynamic Programming?
#%% [markdown]
# 1. èƒŒåŒ…é—®é¢˜  2. æ–æ³¢é‚£å¥‘æ•°åˆ—é˜¶æ¢¯é—®é¢˜ 3 .å­—ç¬¦ä¸²åŒ¹é…KMP
# %% [markdown]
# 4. Can you catch up at least 3 problems which could sloved by Edit Distance?
#%% [markdown]
# 1. æ‹¼å†™æ£€æŸ¥
# 2. DNA é…å¯¹
# 3. å‘½åå®ä½“æŠ½å–
# %% [markdown]
# 5. Please summarize the three main features of Dynamic Programming, and make a concise explain for each feature.
# [markdown]
# 1. æœç´¢èŒƒå›´éå¸¸å¤§ï¼›é’ˆå¯¹æŸä¸ªè§£ï¼Œéœ€è¦æœç´¢è¾ƒå¤§çš„ç©ºé—´
# 2. å­˜åœ¨ç€é‡å¤æœç´¢ï¼› æŸäº›è§£ä¼šè¢«é‡å¤æœç´¢åˆ°ï¼Œä»è€Œå¯ä»¥é‡‡ç”¨æŸ¥è¡¨çš„æ–¹å¼ä¼˜åŒ–æŸ¥è¯¢
# %% [markdown]
# 6. What's the disadvantages of Dynamic Programming? (You may need search by yourself in Internet)
#%% [markdown]
# 1. æ²¡æœ‰ç»Ÿä¸€æ ‡å‡†çš„æ±‚è§£æ¨¡å‹
# 2. å­˜åœ¨ç€ç»´æ•°ç¾éš¾é—®é¢˜ã€‚å½“æŸä¸ªé—®é¢˜æœ‰mä¸ªçŠ¶æ€ï¼Œæ¯ä¸ªçŠ¶æ€æœ‰nç§æ–¹æ³•æ—¶ï¼Œé‚£ä¹ˆéœ€è¦å­˜å‚¨$n^m$ ä¸ªæ•°æ®ï¼Œåœ¨mè¾ƒå¤§æ—¶ï¼Œè¿™æ˜¯ä¸ç°å®çš„
# %% [markdown]
# ## Part 6 Preparation of Project-01
# %% [markdown]
# 1. Using python Flask or Bottle to finish your first simple web app:
# > https://bottlepy.org/
#
# 2. Learn what's the SQL, and try some simple SQL operations:
# > https://www.w3schools.com/sql/sql_intro.asp
#
# 3. Learn what's the HTML ( *ONLY* need to know the basic things)
# > https://getbootstrap.com/; https://www.w3schools.com/html/
# %% [markdown]
# ### (Optinal) Finish the k-person-salesman problem:

# %%


# %%
latitudes = [random.randint(-100, 100) for _ in range(20)]
longitude = [random.randint(-100, 100) for _ in range(20)]


# %%
plt.scatter(latitudes, longitude)

# %% [markdown]
# ç»™å®šä¸€ä¸ªåˆå§‹ç‚¹ ğ‘ƒ, å·²ç» ğ‘˜ä¸ªè½¦è¾†ï¼Œå¦‚ä½•ä»è¯¥ç‚¹å‡ºå‘ï¼Œç»è¿™ k ä¸ªè½¦è¾†ç»è¿‡æ‰€ä»¥çš„ç‚¹å…¨éƒ¨ä¸€æ¬¡ï¼Œè€Œä¸”æ‰€èµ°è¿‡çš„è·¯ç¨‹æœ€çŸ­?
#
# ä¾‹å¦‚ï¼š

# %%
chosen_p = (-50, 10)
chosen_p2 = (1, 30)
chosen_p3 = (99, 15)


# %%


# %%
plt.scatter(latitudes, longitude)
plt.scatter([chosen_p[0]], [chosen_p[1]], color='r')
plt.scatter([chosen_p2[0]], [chosen_p2[1]], color='r')
plt.scatter([chosen_p3[0]], [chosen_p3[1]], color='r')

# %% [markdown]
# shuro
